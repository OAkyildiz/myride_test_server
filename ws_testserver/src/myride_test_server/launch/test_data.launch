<launch>
   <!-- launch video stream -->
    <arg  name="source" default="$(dirname)/../res/sample_vid.mp4"/>

    <include file="$(find video_stream_opencv)/launch/camera.launch" >
        <!-- node name and ros graph name -->
        <arg name="camera_name" value="zed" />
        <!-- means video device 0, /dev/video0 -->
        <arg name="video_stream_provider" value="$(arg source)" />
        <!-- set camera fps to (if the device allows) -->
        <arg name="buffer_queue_size" value="100" />
        <!-- throttling the publishing of frames to -->
        <arg name="fps" value="30" />
        <!-- setting frame_id -->
        <arg name="frame_id" value="zed/rgb_optical_frame" />
        <!-- force a width and height, 0 means no forcing -->
        <arg name="width" value="0"/>
        <arg name="height" value="0"/>
        <!-- visualize on an image_view window the stream generated -->
        <arg name="visualize" value="false" />
        <arg name="loop_videofile" value="true" />

        
    </include>

    <node pkg="myride_test_server" name="dummy" type="dummy_node.py" output="screen"/>

</launch>